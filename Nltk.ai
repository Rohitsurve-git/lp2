

import nltk

nltk.download('punkt_tab')

from nltk import sent_tokenize

text = "Good Morning all. Hope all of you are doing study properly. Thank You"

sent_token = sent_tokenize(text)

print(sent_token)

for sentence in sent_token:
  print(sentence)

"""Word Tokenization"""

from nltk.tokenize import word_tokenize

text1 = "Good Morning all"

word_token = word_tokenize(text1)
print(word_token)

"""Stop Word finding"""

nltk.download('stopwords')

text3 ="""Welcome you to programming knowldge. Lets start with our first tutorial in NLTK. We shall learn basic Nltk here"""

from nltk.corpus import stopwords

stop_words = stopwords.words('english')

from nltk.tokenize import word_tokenize,sent_tokenize

token = word_tokenize(text3)

cleaned_token =[]
for word in token:
    if word not in stop_words:
        cleaned_token.append(word)

print("This is unclean",token)

print("this is clean",cleaned_token)

"""Speech Tagging"""

from nltk.tokenize import word_tokenize,sent_tokenize

nltk.download('averaged_perceptron_tagger')

from nltk import pos_tag

text4 = "Book the ticket."

word_token1 = word_tokenize(text4)
print(word_token1)

pos_tag(word_token1)

"""Count Word

"""

from nltk.corpus import webtext
from nltk.probability import FreqDist

nltk.download('webtext')

file_ids = webtext.fileids()

print(file_ids)

wt_words = webtext.words('pirates.txt')

print(wt_words)

data_analysis = nltk.FreqDist(wt_words)

filter_word = dict([(m,n) for m,n in data_analysis.items() if len(m)>3])

for key in sorted(filter_word):
    print("%s %s" % (key,filter_word[key]))
data_analysis = nltk.FreqDist(filter_word)
